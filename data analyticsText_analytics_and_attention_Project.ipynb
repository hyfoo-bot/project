{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyfoo-bot/project/blob/main/data%20analyticsText_analytics_and_attention_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will make our first foray into text analytics, and build a model for classifying text sentiment. Machine learning will always prefer numbers and matrices, so you will see some new methods for converting text data to numerical format."
      ],
      "metadata": {
        "id": "40GDEYt4T4fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "3k2sOlvKTFWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download a public dataset from UC Irvine that contains sentences collated from Amazon (shopping), IMDB (movie reviews) and Yelp (restaurant reviews). The sentences come with labels where 0 is negative and 1 is positive."
      ],
      "metadata": {
        "id": "ogljP6GKUS1S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxYCYt6fRTiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcab564e-fe06-4339-d3fc-13538b5fd819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-11 13:51:42--  https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘sentiment+labelled+sentences.zip’\n",
            "\n",
            "sentiment+labelled+     [ <=>                ]  82.21K   456KB/s    in 0.2s    \n",
            "\n",
            "2024-11-11 13:51:42 (456 KB/s) - ‘sentiment+labelled+sentences.zip’ saved [84188]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = 'sentiment+labelled+sentences.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "OT7MKWnRSTmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is a great package for virtually any kind of dataset loading and manipulation. You won't go wrong starting with this. Here we take a quick peek at each set of reviews, then mash it all together into a single dataset."
      ],
      "metadata": {
        "id": "yD9Fb9fwU834"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yelp = pd.read_csv('sentiment labelled sentences/yelp_labelled.txt', sep='\\t', header=None)\n",
        "imdb = pd.read_csv('sentiment labelled sentences/imdb_labelled.txt', sep='\\t', header=None)\n",
        "amazon = pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep='\\t', header=None)\n",
        "print(yelp.head(),yelp.shape)\n",
        "print(imdb.head(),imdb.shape)\n",
        "print(amazon.head(), amazon.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSlR0ufGSqcq",
        "outputId": "b8e4dee6-96f6-452b-fb55-ecf515b89ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0  1\n",
            "0                           Wow... Loved this place.  1\n",
            "1                                 Crust is not good.  0\n",
            "2          Not tasty and the texture was just nasty.  0\n",
            "3  Stopped by during the late May bank holiday of...  1\n",
            "4  The selection on the menu was great and so wer...  1 (1000, 2)\n",
            "                                                   0  1\n",
            "0  A very, very, very slow-moving, aimless movie ...  0\n",
            "1  Not sure who was more lost - the flat characte...  0\n",
            "2  Attempting artiness with black & white and cle...  0\n",
            "3       Very little music or anything to speak of.    0\n",
            "4  The best scene in the movie was when Gerardo i...  1 (748, 2)\n",
            "                                                   0  1\n",
            "0  So there is no way for me to plug it in here i...  0\n",
            "1                        Good case, Excellent value.  1\n",
            "2                             Great for the jawbone.  1\n",
            "3  Tied to charger for conversations lasting more...  0\n",
            "4                                  The mic is great.  1 (1000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([yelp, imdb, amazon])\n",
        "print(data.head(),data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAl1SNkMTZqM",
        "outputId": "1c3c815e-c2c5-43a5-ddba-e1acb502d995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0  1\n",
            "0                           Wow... Loved this place.  1\n",
            "1                                 Crust is not good.  0\n",
            "2          Not tasty and the texture was just nasty.  0\n",
            "3  Stopped by during the late May bank holiday of...  1\n",
            "4  The selection on the menu was great and so wer...  1 (2748, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, we need to split the data. Here we only need to split into train and test. Later we will see that the model.fit function already provides a validation split."
      ],
      "metadata": {
        "id": "hjY9MvmaWLFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Write 1 line of code using train_test_split to split the data into 75% training and 25% testing. Hint: check out how we did this in the Trees exercise.\n",
        "train_x, test_x, train_y, test_y = train_test_split(data[0].values, data[1].values, test_size=0.25)\n",
        "# YOUR CODE ENDS"
      ],
      "metadata": {
        "id": "tZjoyHR6WJCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras provides an interesting tool called Tokenizer for pre-processing text data. In machine learning, words are known as tokens. The fit_on_texts method looks at all the text you give it and produces a list of unique words, known as a 'vocabulary', with each word assigned an index number. Then, the texts_to_sequences method converts the sentences to number sequences based on the vocabulary.\n",
        "\n",
        "There is a need to 'pad' the sequences because the sentences have varying lengths. So we set a max sequence length of 32 and pad the shorter sentences with zeroes."
      ],
      "metadata": {
        "id": "ZIOu1PMEX4m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "train_seq = tokenizer.texts_to_sequences(train_x)\n",
        "train_pad = pad_sequences(train_seq, padding='post', maxlen=32)\n",
        "test_seq = tokenizer.texts_to_sequences(test_x)\n",
        "test_pad = pad_sequences(test_seq, padding='post', maxlen=32)\n",
        "print(train_pad)\n",
        "print(train_pad.shape)\n",
        "print(train_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTn-UHbiVTuq",
        "outputId": "20759336-d44f-44b0-edcf-5249368e75b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  59   92  138 ...    0    0    0]\n",
            " [  46   10  180 ...    0    0    0]\n",
            " [  38    3  608 ...    0    0    0]\n",
            " ...\n",
            " [4554 4555  903 ...    0    0    0]\n",
            " [ 220  842   36 ...    0    0    0]\n",
            " [4556 4557  120 ...    0    0    0]]\n",
            "(2061, 32)\n",
            "(2061,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define a simple model. The model starts with an Embedding layer that converts the unique indexes of each word in our sentence sequences into vectors of a high-dimensional space. This is followed by a simple LSTM layer of just 8 units, and ending with a single-neuron that gives a probablistic output from 0 to 1."
      ],
      "metadata": {
        "id": "8U3XPKACZ317"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 32 # embedding vectors of length 32\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim))\n",
        "# YOUR CODE HERE - add 1 LSTM layer with 8 units\n",
        "model.add(layers.LSTM(8))\n",
        "# YOUR CODE ENDS\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "CSYLYBaiZ4BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using model.fit, the flag validation_split allows the code to split off a fraction of the data for validation. 'Accuracy' refers to training accuracy and should quickly hit >90%, but that doesn't represent your model's performance on unseen data. Be careful to look at val_accuracy when evaluating the model."
      ],
      "metadata": {
        "id": "ENJW5jOeb_kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# write 1 line of code using model.fit to train the model. Use the following settings: batch_size=8, epochs=5, verbose=1, validation_split=0.2\n",
        "model.fit(train_pad,train_y,batch_size=8,epochs=5,verbose=1,validation_split=0.2)\n",
        "# YOUR CODE ENDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpX7syydbVSl",
        "outputId": "60b45451-75b2-4b6a-8f0b-40f3a990e0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4875 - loss: 0.6940 - val_accuracy: 0.6029 - val_loss: 0.6623\n",
            "Epoch 2/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7795 - loss: 0.5479 - val_accuracy: 0.6877 - val_loss: 0.6765\n",
            "Epoch 3/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8625 - loss: 0.3878 - val_accuracy: 0.7264 - val_loss: 0.6559\n",
            "Epoch 4/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9074 - loss: 0.2899 - val_accuracy: 0.7191 - val_loss: 0.7253\n",
            "Epoch 5/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9433 - loss: 0.2322 - val_accuracy: 0.7288 - val_loss: 0.6702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78885a0151e0>"
            ]
          },
          "metadata": {},
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model looks passable (val_accuracy around 75%) and will probably do even better with longer training and some tweaking of hyperparameters. But here we will experiment with Attention, a powerful mechanism for weighting the relative importance of different parts of a sentence.\n",
        "\n",
        "We will implement the simplest form of Attention that was first proposed by Bahdanau (2014) for improving LSTM performance. Rather than use only the final output (hidden state) of the LSTM, we will learn a weighting of all the hidden states emitted from all the LSTM units, such the layer outputs a weighted sum of a linear combination of the states. This sounds simple enough but already requires a bit more work to write our own layer. Most of the work is done for you."
      ],
      "metadata": {
        "id": "FFFHum6Kcdvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class Attention(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Attention,self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # set up the layer to have a set of linear weights that match the length of the input\n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
        "                               initializer=\"zeros\")\n",
        "\n",
        "        super(Attention,self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # YOUR CODE HERE\n",
        "        # 1 line of code that performs a dot product of the input x with the weights and adds the bias term\n",
        "        # the dot product of u and v is implemented as K.dot(u,v)\n",
        "        dot_product = K.dot(x,self.W)+self.b\n",
        "        # YOUR CODE ENDS\n",
        "        e = K.tanh(dot_product)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x*a\n",
        "\n",
        "        return K.sum(output, axis=1)"
      ],
      "metadata": {
        "id": "rqZYydluePHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a new model, and here we add our new Attention layer. Notice that the LSTM now is set to return sequences, which is needed for the attention calculation."
      ],
      "metadata": {
        "id": "-cFdwFqti5Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model initialization\n",
        "model = keras.Sequential()\n",
        "# embedding layer\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim))\n",
        "#LSTM(64),\n",
        "model.add(layers.LSTM(8,return_sequences=True))\n",
        "\n",
        "# YOUR CODE HERE - add our homemade layer\n",
        "model.add(Attention())\n",
        "# YOUR CODE ENDS\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "aLq61PtsLNJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE - same code you wrote above to train the model\n",
        "model.fit(train_pad,train_y,batch_size=8,epochs=5,verbose=1,validation_split=0.2)\n",
        "# YOUR CODE ENDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUTg7dN1Liar",
        "outputId": "3515f675-48d2-4af4-a73c-a73e80f07e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5382 - loss: 0.6902 - val_accuracy: 0.6731 - val_loss: 0.6147\n",
            "Epoch 2/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8285 - loss: 0.4598 - val_accuracy: 0.7700 - val_loss: 0.4944\n",
            "Epoch 3/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9296 - loss: 0.2548 - val_accuracy: 0.7821 - val_loss: 0.5244\n",
            "Epoch 4/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9374 - loss: 0.2145 - val_accuracy: 0.7676 - val_loss: 0.6089\n",
            "Epoch 5/5\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1463 - val_accuracy: 0.7530 - val_loss: 0.6745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x788859a55570>"
            ]
          },
          "metadata": {},
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There few percentage points improvement up to around 80% validation accuracy."
      ],
      "metadata": {
        "id": "bOBS9Pzrjbqp"
      }
    }
  ]
}